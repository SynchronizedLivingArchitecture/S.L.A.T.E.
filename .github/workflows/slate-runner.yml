# ═══════════════════════════════════════════════════════════════════════════════
# SLATE Self-Hosted Runner — Full System Validation
# Modified: 2026-02-09T06:45:00Z | Author: COPILOT | Change: Create runner workflow
# ═══════════════════════════════════════════════════════════════════════════════
# Runs the complete SLATE system stack on the self-hosted runner to validate
# GPU acceleration, ML pipelines, agent systems, and SDK integrity.
#
# Triggers: push to main branches, manual dispatch, nightly schedule
# Target: self-hosted runner with labels [self-hosted, slate, gpu, windows]
# ═══════════════════════════════════════════════════════════════════════════════

name: "SLATE Runner: Full System"

on:
  push:
    branches: [main, "001-data-viz-dashboard"]
    paths:
      - "aurora_core/**"
      - "agents/**"
      - "tests/**"
      - "requirements.txt"
      - "pyproject.toml"
  workflow_dispatch:
    inputs:
      run_gpu_benchmarks:
        description: "Run GPU benchmarks (slower)"
        required: false
        type: boolean
        default: false
      run_ml_pipeline:
        description: "Run ML training pipeline"
        required: false
        type: boolean
        default: false
  schedule:
    - cron: "0 4 * * *"  # 4 AM UTC daily

env:
  SLATE_WORKSPACE: ${{ github.workspace }}
  SLATE_RUNNER: "true"
  PYTHONIOENCODING: "utf-8"

jobs:
  # ─── Environment Validation ───────────────────────────────────────────────
  environment:
    name: "Validate SLATE Environment"
    runs-on: [self-hosted, slate, gpu, windows]
    timeout-minutes: 10
    outputs:
      gpu_available: ${{ steps.gpu.outputs.available }}
      gpu_count: ${{ steps.gpu.outputs.count }}
      slate_version: ${{ steps.sdk.outputs.version }}
    steps:
      - uses: actions/checkout@v4

      - name: SLATE Environment Check
        id: env
        shell: pwsh
        run: |
          Write-Host "=== SLATE Runner Environment ===" -ForegroundColor Cyan
          Write-Host "Workspace: ${{ github.workspace }}"
          Write-Host "Runner OS: ${{ runner.os }}"
          Write-Host "Runner Arch: ${{ runner.arch }}"

          # Check for SLATE venv
          $venvPython = Join-Path ${{ github.workspace }} ".venv\Scripts\python.exe"
          if (Test-Path $venvPython) {
            Write-Host "SLATE venv: OK ($venvPython)"
            & $venvPython --version
          } else {
            Write-Host "SLATE venv: Not found, using system Python"
            python --version
          }

      - name: GPU Detection
        id: gpu
        shell: pwsh
        run: |
          try {
            $gpuInfo = & nvidia-smi --query-gpu=name,memory.total,compute_cap --format=csv,noheader 2>$null
            if ($LASTEXITCODE -eq 0 -and $gpuInfo) {
              $gpuCount = ($gpuInfo -split "`n" | Where-Object { $_.Trim() }).Count
              Write-Host "GPUs detected: $gpuCount"
              $gpuInfo -split "`n" | ForEach-Object { Write-Host "  - $_" }
              echo "available=true" >> $env:GITHUB_OUTPUT
              echo "count=$gpuCount" >> $env:GITHUB_OUTPUT
            } else {
              echo "available=false" >> $env:GITHUB_OUTPUT
              echo "count=0" >> $env:GITHUB_OUTPUT
            }
          } catch {
            echo "available=false" >> $env:GITHUB_OUTPUT
            echo "count=0" >> $env:GITHUB_OUTPUT
          }

      - name: CUDA Toolkit Check
        if: steps.gpu.outputs.available == 'true'
        shell: pwsh
        run: |
          try {
            & nvcc --version 2>$null
            if ($LASTEXITCODE -ne 0) {
              Write-Host "CUDA toolkit not in PATH (nvidia-smi available, nvcc not found)"
            }
          } catch {
            Write-Host "nvcc not available"
          }

      - name: SDK Version
        id: sdk
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          $version = & $python -c "import aurora_core; print(getattr(aurora_core, '__version__', 'unknown'))" 2>$null
          if ($LASTEXITCODE -eq 0) {
            Write-Host "SLATE SDK: v$version"
            echo "version=$version" >> $env:GITHUB_OUTPUT
          } else {
            Write-Host "SDK not importable"
            echo "version=unknown" >> $env:GITHUB_OUTPUT
          }

  # ─── Core System Tests ────────────────────────────────────────────────────
  core-systems:
    name: "Core SLATE Systems"
    runs-on: [self-hosted, slate, gpu, windows]
    needs: environment
    timeout-minutes: 15
    steps:
      - uses: actions/checkout@v4

      - name: SLATE Status
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python aurora_core/slate_status.py --quick
          if ($LASTEXITCODE -ne 0) {
            Write-Host "::warning::slate_status.py returned non-zero"
          }

      - name: SLATE Runtime Check
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python aurora_core/slate_runtime.py --check-all
          if ($LASTEXITCODE -ne 0) {
            Write-Host "::warning::slate_runtime.py returned non-zero"
          }

      - name: SDK Import Validation
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -c @"
          import aurora_core
          from aurora_core import slate_status
          from aurora_core import slate_runtime
          print('Core SDK imports: OK')

          # Test runner manager
          from aurora_core.slate_runner_manager import SlateRunnerManager
          mgr = SlateRunnerManager()
          status = mgr.get_status()
          print(f'Runner status: installed={status[\"installed\"]}, provisioned={status[\"provisioned\"]}')
          print(f'GPU: {status[\"gpu\"][\"gpu_count\"]} detected')
          print(f'Labels: {status[\"labels\"]}')
          "@

      - name: Hardware Optimizer
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          if (Test-Path "aurora_core/slate_hardware_optimizer.py") {
            & $python aurora_core/slate_hardware_optimizer.py 2>$null
            if ($LASTEXITCODE -ne 0) {
              Write-Host "::warning::Hardware optimizer returned non-zero"
            }
          } else {
            Write-Host "Hardware optimizer not found, skipping"
          }

      - name: Tech Tree Status
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          if (Test-Path "aurora_core/tech_tree.json") {
            & $python -c @"
          import json
          with open('aurora_core/tech_tree.json') as f:
              tree = json.load(f)
          total = len(tree) if isinstance(tree, list) else len(tree.get('nodes', tree.get('tasks', [])))
          print(f'Tech tree: {total} nodes loaded')
          "@
          } else {
            Write-Host "Tech tree not found"
          }

  # ─── Dashboard & API ──────────────────────────────────────────────────────
  dashboard:
    name: "Dashboard & API"
    runs-on: [self-hosted, slate, gpu, windows]
    needs: environment
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4

      - name: Dashboard Import Test
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -c @"
          try:
              from agents.aurora_dashboard_server import app
              print('Dashboard server: importable')
          except ImportError as e:
              print(f'Dashboard import warning: {e}')
          "@

      - name: Dashboard Smoke Test
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -c @"
          import asyncio, sys
          try:
              from agents.aurora_dashboard_server import app
              from fastapi.testclient import TestClient
              client = TestClient(app)
              resp = client.get('/api/status')
              if resp.status_code == 200:
                  print(f'Dashboard API /api/status: {resp.status_code} OK')
              else:
                  print(f'Dashboard API /api/status: {resp.status_code}')
          except Exception as e:
              print(f'Dashboard smoke test skipped: {e}')
          "@

      - name: Install API Test
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -c @"
          try:
              from agents.install_api import app
              print('Install API: importable')
          except Exception as e:
              print(f'Install API: {e}')
          "@

  # ─── Agent System ─────────────────────────────────────────────────────────
  agents:
    name: "Agent System Validation"
    runs-on: [self-hosted, slate, gpu, windows]
    needs: core-systems
    timeout-minutes: 15
    steps:
      - uses: actions/checkout@v4

      - name: Agent Module Imports
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -c @"
          modules = [
              'aurora_agent_coordinator',
              'aurora_agent_intelligence',
              'aurora_agent_v2',
              'aurora_cycle_evaluator',
              'aurora_cycle_monitor',
              'aurora_workspace_analyzer',
          ]
          ok = 0
          for mod in modules:
              try:
                  __import__(mod)
                  print(f'  OK  {mod}')
                  ok += 1
              except Exception as e:
                  print(f'  SKIP {mod}: {e}')
          print(f'\nAgent modules: {ok}/{len(modules)} importable')
          "@

      - name: Task System Check
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -c @"
          import json, os
          task_files = ['clean_tasks.json', 'aurora_strategic_tasks.json', 'approval_queue.json']
          for tf in task_files:
              if os.path.exists(tf):
                  with open(tf) as f:
                      data = json.load(f)
                  count = len(data) if isinstance(data, list) else len(data.get('tasks', []))
                  print(f'  {tf}: {count} entries')
              else:
                  print(f'  {tf}: not found')
          "@

  # ─── GPU Tests ────────────────────────────────────────────────────────────
  gpu-tests:
    name: "GPU & CUDA Tests"
    runs-on: [self-hosted, slate, gpu, windows]
    needs: environment
    if: needs.environment.outputs.gpu_available == 'true'
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@v4

      - name: PyTorch GPU Test
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -c @"
          try:
              import torch
              print(f'PyTorch version: {torch.__version__}')
              print(f'CUDA available: {torch.cuda.is_available()}')
              if torch.cuda.is_available():
                  print(f'CUDA version: {torch.version.cuda}')
                  for i in range(torch.cuda.device_count()):
                      name = torch.cuda.get_device_name(i)
                      mem = torch.cuda.get_device_properties(i).total_mem / 1e9
                      print(f'  GPU {i}: {name} ({mem:.1f} GB)')
                  # Quick tensor test
                  t = torch.randn(1000, 1000, device='cuda')
                  result = torch.mm(t, t)
                  print(f'  Matrix multiply test: OK ({result.shape})')
                  del t, result
                  torch.cuda.empty_cache()
          except ImportError:
              print('PyTorch not installed')
          except Exception as e:
              print(f'GPU test error: {e}')
          "@

      - name: VRAM Status
        shell: pwsh
        run: |
          & nvidia-smi --query-gpu=name,memory.used,memory.total,utilization.gpu --format=csv,noheader

      - name: GPU Benchmark
        if: github.event_name == 'workflow_dispatch' && inputs.run_gpu_benchmarks
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          if (Test-Path "aurora_core/slate_benchmark.py") {
            & $python aurora_core/slate_benchmark.py --json
          }

  # ─── ML Pipeline ──────────────────────────────────────────────────────────
  ml-pipeline:
    name: "ML Pipeline Validation"
    runs-on: [self-hosted, slate, gpu, windows]
    needs: [environment, gpu-tests]
    if: |
      always() &&
      needs.environment.result == 'success' &&
      (github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && inputs.run_ml_pipeline))
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4

      - name: ML Orchestrator Status
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          if (Test-Path "aurora_core/ml_orchestrator.py") {
            & $python aurora_core/ml_orchestrator.py --status
          } else {
            Write-Host "ML orchestrator not found"
          }

      - name: ML Index
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          if (Test-Path "aurora_core/ml_orchestrator.py") {
            & $python aurora_core/ml_orchestrator.py --index-now
          }

      - name: ML Training Cycle
        shell: pwsh
        timeout-minutes: 20
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          if (Test-Path "aurora_core/ml_orchestrator.py") {
            & $python aurora_core/ml_orchestrator.py --train-now
          }

  # ─── Package Validation ───────────────────────────────────────────────────
  package:
    name: "Package & Build"
    runs-on: [self-hosted, slate, gpu, windows]
    needs: environment
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4

      - name: Package Build Test
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -m build --sdist --no-isolation 2>$null
          if ($LASTEXITCODE -eq 0) {
            Write-Host "Package build: OK"
            Get-ChildItem dist/ -Name
          } else {
            Write-Host "::warning::Package build failed (build module may not be installed)"
          }

      - name: Package Manager Validate
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          if (Test-Path "aurora_core/slate_package_manager.py") {
            & $python aurora_core/slate_package_manager.py validate
          }

  # ─── Summary ──────────────────────────────────────────────────────────────
  summary:
    name: "Runner Summary"
    runs-on: [self-hosted, slate, gpu, windows]
    needs: [environment, core-systems, dashboard, agents, gpu-tests, ml-pipeline, package]
    if: always()
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v4

      - name: Generate Summary
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          Write-Host ""
          Write-Host "========================================" -ForegroundColor Cyan
          Write-Host "  SLATE Self-Hosted Runner Summary" -ForegroundColor Cyan
          Write-Host "========================================" -ForegroundColor Cyan
          Write-Host ""
          Write-Host "Environment:  ${{ needs.environment.result }}"
          Write-Host "Core Systems: ${{ needs.core-systems.result }}"
          Write-Host "Dashboard:    ${{ needs.dashboard.result }}"
          Write-Host "Agents:       ${{ needs.agents.result }}"
          Write-Host "GPU Tests:    ${{ needs.gpu-tests.result }}"
          Write-Host "ML Pipeline:  ${{ needs.ml-pipeline.result }}"
          Write-Host "Package:      ${{ needs.package.result }}"
          Write-Host ""
          Write-Host "SDK Version:  ${{ needs.environment.outputs.slate_version }}"
          Write-Host "GPU Count:    ${{ needs.environment.outputs.gpu_count }}"
          Write-Host ""

      - name: Write Job Summary
        shell: pwsh
        run: |
          $summary = @"
          ## SLATE Self-Hosted Runner Report

          | System | Status |
          |--------|--------|
          | Environment | ${{ needs.environment.result }} |
          | Core Systems | ${{ needs.core-systems.result }} |
          | Dashboard & API | ${{ needs.dashboard.result }} |
          | Agent System | ${{ needs.agents.result }} |
          | GPU Tests | ${{ needs.gpu-tests.result }} |
          | ML Pipeline | ${{ needs.ml-pipeline.result }} |
          | Package & Build | ${{ needs.package.result }} |

          **SDK Version:** ${{ needs.environment.outputs.slate_version }}
          **GPUs:** ${{ needs.environment.outputs.gpu_count }}
          **Runner:** ``self-hosted, slate, gpu, windows``
          "@
          $summary | Out-File -FilePath $env:GITHUB_STEP_SUMMARY -Encoding utf8 -Append
