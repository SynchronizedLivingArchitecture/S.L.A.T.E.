# Modified: 2026-02-07T04:56:45Z | Author: COPILOT | Change: Normalize paths and clean workflow artifacts
name: SLATE CI

on:
  push:
    branches: [main, develop, 'feature/*']
    paths-ignore: ['*.md', 'docs/**', '.github/*.md', 'specs/**']
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

# Modified: 2026-02-07T08:30:00Z | Author: COPILOT | Change: Fix concurrency group for PR-triggered workflows
concurrency:
  group: ci-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

defaults:
  run:
    shell: powershell

jobs:
  lint:
    name: Lint & Format
    runs-on: [self-hosted, slate]
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v4
      - name: Setup Python
        run: |
          "$env:GITHUB_WORKSPACE\\.venv\\Scripts" | Out-File -Append $env:GITHUB_PATH
      - name: Ruff lint
        run: |
          pip install ruff --quiet 2>$null
          ruff check slate/ agents/ --output-format=github
        continue-on-error: true
      - name: Ruff format check
        run: ruff format --check slate/ agents/ --diff
        continue-on-error: true

  unit-tests:
    name: Unit Tests
    runs-on: [self-hosted, slate]
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@v4
      - name: Setup Python
        run: |
          "$env:GITHUB_WORKSPACE\\.venv\\Scripts" | Out-File -Append $env:GITHUB_PATH
      - name: Install test deps
        run: pip install pytest pytest-cov pytest-asyncio --quiet 2>$null
        continue-on-error: true
      - name: Run tests
        run: python -m pytest tests/ -v --tb=short --ignore=tests/integration/ -x
        continue-on-error: true

  sdk-validation:
    name: SDK Validation
    runs-on: [self-hosted, slate]
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v4
      - name: Setup Python
        run: |
          "$env:GITHUB_WORKSPACE\\.venv\\Scripts" | Out-File -Append $env:GITHUB_PATH
      - name: Verify SDK imports
        run: |
          python -c "import slate; print(f'SDK v{slate.__version__}')"
          python -c "import slate.slate_status; print('slate_status OK')"
          python -c "import slate.slate_runtime; print('slate_runtime OK')"
          python -c "import slate.slate_hardware_optimizer; print('hardware_optimizer OK')"
      - name: Version sync
        run: |
          python -c @"
          import tomllib
          with open('pyproject.toml', 'rb') as f:
              c = tomllib.load(f)
          v = c['project']['version']
          import slate
          assert slate.__version__ == v, f'Mismatch: {slate.__version__} != {v}'
          print(f'Version sync OK: {v}')
          "@

  security:
    name: Security Scan
    runs-on: [self-hosted, slate]
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4
      - name: Setup Python
        run: |
          "$env:GITHUB_WORKSPACE\\.venv\\Scripts" | Out-File -Append $env:GITHUB_PATH
      - name: Bandit scan
        run: |
          pip install bandit --quiet 2>$null
          bandit -r slate/ agents/ -ll -ii -x "**/test*"
        continue-on-error: true

  slate-checks:
    name: SLATE Quick Checks
    runs-on: [self-hosted, slate]
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v4
      - name: Setup Python
        run: |
          "$env:GITHUB_WORKSPACE\\.venv\\Scripts" | Out-File -Append $env:GITHUB_PATH
      - name: Validate Tech Tree
        run: |
          python -c @"
          import json
          with open('.slate_tech_tree/tech_tree.json', 'r', encoding='utf-8') as f:
              tree = json.load(f)
          nodes = tree.get('nodes', [])
          completed = sum(1 for n in nodes if n.get('status') == 'complete')
          print(f'Tech Tree: {completed}/{len(nodes)} complete')
          "@
      - name: Validate Task Queue
        run: |
          python -c @"
          import json
          with open('current_tasks.json', 'r', encoding='utf-8') as f:
              data = json.load(f)
          tasks = data.get('tasks', data) if isinstance(data, dict) else data
          if isinstance(tasks, list):
              pending = sum(1 for t in tasks if t.get('status') == 'pending')
              print(f'Task Queue: {pending} pending tasks')
          else:
              print('Task queue OK')
          "@
      - name: Validate pyproject.toml
        run: |
          python -c @"
          import tomllib
          with open('pyproject.toml', 'rb') as f:
              config = tomllib.load(f)
          name = config['project']['name']
          ver = config['project']['version']
          print(f'Project: {name} v{ver}')
          "@

  gpu-validation:
    name: GPU Compute Validation
    runs-on: [self-hosted, slate, gpu]
    timeout-minutes: 10
    env:
      CUDA_VISIBLE_DEVICES: '0,1'
    steps:
      - uses: actions/checkout@v4
      - name: Setup Python
        run: |
          "$env:GITHUB_WORKSPACE\\.venv\\Scripts" | Out-File -Append $env:GITHUB_PATH
      - name: CUDA Environment Check
        run: |
          nvidia-smi --query-gpu=index,name,driver_version,memory.total --format=csv
      - name: GPU Compute Validation
        run: |
          python tests/test_gpu_compute.py

  ai-code-review:
    name: AI Code Review
    runs-on: [self-hosted, slate]
    if: github.event_name == 'pull_request'
    timeout-minutes: 15
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Setup Python
        run: |
          "$env:GITHUB_WORKSPACE\\.venv\\Scripts" | Out-File -Append $env:GITHUB_PATH
      - name: Check Ollama
        id: ollama
        run: |
          $available = $false
          try {
            $response = Invoke-RestMethod -Uri "http://127.0.0.1:11434/api/tags" -TimeoutSec 5
            if ($response) { $available = $true }
          } catch { }
          "available=$available" | Out-File -Append $env:GITHUB_OUTPUT
      - name: AI Review Changed Files
        if: steps.ollama.outputs.available == 'True'
        run: |
          Write-Host "AI-powered code review for PR #${{ github.event.pull_request.number }}"
          Write-Host ""

          # Analyze recently changed files
          python slate/slate_ai_orchestrator.py --analyze-recent --json > ai_review.json

          $review = Get-Content ai_review.json -Raw | ConvertFrom-Json
          Write-Host "Files analyzed: $($review.files_analyzed)"
          Write-Host "Issues found: $($review.issues_found)"

          # Add review summary
          "## AI Code Review" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "**Files Analyzed**: $($review.files_analyzed)" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "**Issues Found**: $($review.issues_found)" | Out-File -Append $env:GITHUB_STEP_SUMMARY

  summary:
    name: CI Summary
    runs-on: [self-hosted, slate]
    needs: [lint, unit-tests, sdk-validation, security, slate-checks, gpu-validation, ai-code-review]
    if: always()
    steps:
      - name: Generate summary
        run: |
          "## SLATE CI Summary" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "| Job | Status |" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "|-----|--------|" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "| Lint | ${{ needs.lint.result }} |" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "| Unit Tests | ${{ needs.unit-tests.result }} |" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "| SDK Validation | ${{ needs.sdk-validation.result }} |" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "| Security | ${{ needs.security.result }} |" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "| SLATE Checks | ${{ needs.slate-checks.result }} |" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "| GPU Validation | ${{ needs.gpu-validation.result }} |" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "| AI Code Review | ${{ needs.ai-code-review.result || 'skipped' }} |" | Out-File -Append $env:GITHUB_STEP_SUMMARY
